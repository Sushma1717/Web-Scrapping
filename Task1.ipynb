{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the paginated webpage that you want to scrape\n",
    "url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "\n",
    "# Initializing an empty list to store the data that you scrape\n",
    "data = []\n",
    "\n",
    "# Setting the initial page number and the increment that you want to use to paginate through the webpage\n",
    "page_num = 1\n",
    "page_incr = 1\n",
    "page_size = 100\n",
    "\n",
    "# maximum number of pages to be scraped\n",
    "max_pages = 20\n",
    "\n",
    "# Set the URL of the webpage to be scraped \n",
    "paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "# A while loop to paginate through the webpage and scrape the data\n",
    "while page_num <= max_pages:\n",
    "\n",
    "    print(f\"Scraping page {page_num}\")\n",
    "\n",
    "    # A GET request to the paginated URL\n",
    "    response = requests.get(paginated_url)\n",
    "\n",
    "    # Parsing the response using BeautifulSoup\n",
    "    parsed_content = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Finding all the elements on the page that contain the data to be scraped\n",
    "    elements = parsed_content.find_all(\"div\",class_ = \"body\")\n",
    "\n",
    "    # Looping through the elements and extract the data that you want to scrape\n",
    "    for element in elements:\n",
    "        header = element.find(\"h2\",class_ = \"text_header\").text.replace(\"\\n\", \" \")\n",
    "        sub_header = element.find(\"h3\",class_ = \"text_sub_header\").text.replace(\"\\n\", \" \")\n",
    "        content = element.find(\"div\",class_ = \"text_content\").text.replace(\"\\n\", \" \")\n",
    "        \n",
    "        data.append([header,sub_header,content])\n",
    "\n",
    "    # Increasing the page number and setting the paginated URL to the new page\n",
    "    page_num += page_incr\n",
    "    paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    print(f\"   ---> {len(data)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>PERSONAL INFO</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"there is a race to the bottom\"</td>\n",
       "      <td>Thomas Kowalski (United States) 19th January...</td>\n",
       "      <td>Not Verified | It seems that there is a race t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"need to cancel the ticket and rebook\"</td>\n",
       "      <td>Reyes Diaz (United Kingdom) 19th January 2023</td>\n",
       "      <td>Not Verified |  As a Spanish born individual l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"very friendly cabin crew\"</td>\n",
       "      <td>1 reviews    S Zarhas (United Kingdom) 18th ...</td>\n",
       "      <td>A rather empty and quiet flight to Tel Aviv, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"a good drinks and food service\"</td>\n",
       "      <td>E Smyth (United Kingdom) 17th January 2023</td>\n",
       "      <td>Easy check in and staff member was polite and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"you should let me use the lounge\"</td>\n",
       "      <td>Jozef Kis (United Kingdom) 17th January 2023</td>\n",
       "      <td>Being a silver flyer and booking a flight thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>\"a mediocre service\"</td>\n",
       "      <td>M Steger (Germany) 5th June 2016</td>\n",
       "      <td>A mediocre service on this airline flying from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>\"good fare from their sale\"</td>\n",
       "      <td>Bill Atkins (United Kingdom) 5th June 2016</td>\n",
       "      <td>MAN to LHR with personable crew who did the br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>\"slowed down the process\"</td>\n",
       "      <td>12 reviews    T Long (United Kingdom) 4th Ju...</td>\n",
       "      <td>London to Bucharest with British Airways. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>\"does what you would expect\"</td>\n",
       "      <td>Simon Fowler (United Kingdom) 4th June 2016</td>\n",
       "      <td>Shambolic check-in at New York JFK following t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>\"flight had been over booked\"</td>\n",
       "      <td>J Kirkpatrick (United Kingdom) 3rd June 2016</td>\n",
       "      <td>Booked flights with British Airways rather tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      REVIEW  \\\n",
       "0            \"there is a race to the bottom\"   \n",
       "1     \"need to cancel the ticket and rebook\"   \n",
       "2                 \"very friendly cabin crew\"   \n",
       "3           \"a good drinks and food service\"   \n",
       "4         \"you should let me use the lounge\"   \n",
       "...                                      ...   \n",
       "1995                    \"a mediocre service\"   \n",
       "1996             \"good fare from their sale\"   \n",
       "1997               \"slowed down the process\"   \n",
       "1998            \"does what you would expect\"   \n",
       "1999           \"flight had been over booked\"   \n",
       "\n",
       "                                          PERSONAL INFO  \\\n",
       "0       Thomas Kowalski (United States) 19th January...   \n",
       "1         Reyes Diaz (United Kingdom) 19th January 2023   \n",
       "2       1 reviews    S Zarhas (United Kingdom) 18th ...   \n",
       "3            E Smyth (United Kingdom) 17th January 2023   \n",
       "4          Jozef Kis (United Kingdom) 17th January 2023   \n",
       "...                                                 ...   \n",
       "1995                   M Steger (Germany) 5th June 2016   \n",
       "1996         Bill Atkins (United Kingdom) 5th June 2016   \n",
       "1997    12 reviews    T Long (United Kingdom) 4th Ju...   \n",
       "1998        Simon Fowler (United Kingdom) 4th June 2016   \n",
       "1999       J Kirkpatrick (United Kingdom) 3rd June 2016   \n",
       "\n",
       "                                                CONTENT  \n",
       "0     Not Verified | It seems that there is a race t...  \n",
       "1     Not Verified |  As a Spanish born individual l...  \n",
       "2     A rather empty and quiet flight to Tel Aviv, v...  \n",
       "3     Easy check in and staff member was polite and ...  \n",
       "4     Being a silver flyer and booking a flight thro...  \n",
       "...                                                 ...  \n",
       "1995  A mediocre service on this airline flying from...  \n",
       "1996  MAN to LHR with personable crew who did the br...  \n",
       "1997  London to Bucharest with British Airways. The ...  \n",
       "1998  Shambolic check-in at New York JFK following t...  \n",
       "1999  Booked flights with British Airways rather tha...  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Coverting the list data into a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = [\"REVIEW\",\"PERSONAL INFO\",\"CONTENT\"]\n",
    "\n",
    "#Removing unwanted text(first text preprocessing)\n",
    "df.replace(re.compile(r'\\s*✅ Trip Verified \\|\\s*'), '', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving data into a csv\n",
    "df.to_csv(r\"data\\BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified | It seems that there is a race t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  As a Spanish born individual l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A rather empty and quiet flight to Tel Aviv, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy check in and staff member was polite and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Being a silver flyer and booking a flight thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>A mediocre service on this airline flying from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>MAN to LHR with personable crew who did the br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>London to Bucharest with British Airways. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Shambolic check-in at New York JFK following t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Booked flights with British Airways rather tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                CONTENT\n",
       "0     Not Verified | It seems that there is a race t...\n",
       "1     Not Verified |  As a Spanish born individual l...\n",
       "2     A rather empty and quiet flight to Tel Aviv, v...\n",
       "3     Easy check in and staff member was polite and ...\n",
       "4     Being a silver flyer and booking a flight thro...\n",
       "...                                                 ...\n",
       "1995  A mediocre service on this airline flying from...\n",
       "1996  MAN to LHR with personable crew who did the br...\n",
       "1997  London to Bucharest with British Airways. The ...\n",
       "1998  Shambolic check-in at New York JFK following t...\n",
       "1999  Booked flights with British Airways rather tha...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis_df = df.drop([\"REVIEW\",\"PERSONAL INFO\"], axis=1)\n",
    "sentiment_analysis_df.replace(re.compile(r'\\s*✅ Verified Review \\|\\s*'), '', inplace=True)\n",
    "sentiment_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "sentiment_analysis_df.to_csv(\"data\\sentiment_content.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
